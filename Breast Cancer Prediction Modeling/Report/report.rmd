---
title: "Breast Cancer Prediction Modeling using Logistic Regression"
author: "Dr Ami Soni"
output: html_document  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

## Introduction

In this project, I will develop a logistic regression model to predict the likelihood of breast cancer based on various clinical and demographic factors. The dataset used for this analysis is sourced from the UCI Machine Learning Repository and contains information about patient`s health metrics and whether they have been diagnosed with breast cancer. The dataset includes features such as diagnosis, tumor size, and other relevant medical indicators. The goal is to classify tumors as malignant or benign. The dataset is available on kaggle here: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data?resource=download.

The learning objectives of this project are:
1. Import and preprocess the dataset to handle missing values and categorical variables.
2. Explore the data through descriptive statistics and visualizations to understand the distribution of features.
3. Split the dataset into training and testing sets to evaluate model performance.
4. Build a logistic regression model to predict breast cancer diagnosis.
5. Evaluate the model using metrics such as accuracy, precision, recall, and the ROC curve.   
6. Interpret the model coefficients to understand the impact of each feature on the prediction.

## Load Necessary Libraries

This step ensures that all necessary libraries are available and loaded for data manipulation, visualization, and modeling. The `pacman` package is used to load or install the necessary libraries efficiently, such as :

- `tidyverse` for data manipulation and visualization,
- `caret` for machine learning functions,
- `caTools` for data splitting,
- `pROC` and `ROCR` for ROC curve analysis and plotting,
- `GGally` for advanced visualizations, 
- `knitr` for dynamic report generation, and
- `stats` for statistical functions.


```{r load-packages}
pacman::p_load(tidyverse,  # For data manipulation and visualization     
                caret,      # For machine learning functions
                rio,        # For data import/export        
                caTools,    # For data splitting
                pROC,       # For ROC curve analysis
                ROCR,      # For ROC curve plotting
                GGally,    # For advanced visualizations         
                knitr,   #  For dynamic report generation
                stats      # For statistical functions)
```

## Load the Dataset

The dataset is loaded from a CSV file  "data.csv" available from kaggle website here:  https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data?resource=download. The `import` function from `rio` package is used to read the data into R, and the `head` function displays the first few rows of the dataset to give an overview of its structure and contents.

```{r load-data}

data <- import("data.csv")  # Replace with the actual path to your dataset
head(data)

data <- data[-33]

``` 

## Data Preprocessing 

This step prepares the data for analysis:

- *Handling missig values*: Missing values are identified using is.na() and removed using na.omit().
- *Categorical variable conversion*: The target variable 'diagnosis' is converted to a factor to facilitate classification (e.g. Malignant and Benign).
- *Dropping unnecessary columns*: Columns that do not contribute to the analysis, such as IDs, are removed using select() from dplyr.
- *Data structure*: The str() function is used to check the structure of the dataset after preprocessing to ensure that all variables are in the correct format.


```{r data-preprocessing}

# Check for missing values


data <- data %>% select(-33)

sum(is.na(data))

# Convert categorical variables to factors

data <- data %>% mutate(diagnosis = ifelse(diagnosis == "M", 1, 0), levels = c(0,1))


# Drop unnecessary columns )

 

str(data)

```     


## Exploratory Data Analysis (EDA)

Exploratory Data Analysis (EDA) helps understand the dataset structure and relationship between variables.

- *Summary statistics*: The summary() function provides descriptive statistics for each variable.

- *Distribution of target variable*: A bar plot visualizes the distribution of the target variable 'diagnosis'.

- *Pairwise scatter plots*: The ggpairs() function from GGally creates pairwise scatter plots to visualize relationships between features, colored by the target variable.

- *Correlation matrix*: A heatmap visualizes the correlation between numerical features, helping identify multicollinearity. 


```{r eda} 

# Summary statistics

summary(data) 

```

```{r eda-plots, warning=FALSE, message=FALSE}

# Visualize the distribution of the target variable
ggplot(data, aes(x = diagnosis)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Distribution of Breast Cancer Diagnosis", x = "Diagnosis", y = "Count")   

table(data$diagnosis)

```
The dataset reveals that out of total cases, 212 are classifed as malignant, while 357 are classified ad benign.



## Split the Data into Training and Testing Sets

The dataset is split into training (70%) and testing (30%) sets using sample.split() function from the `caTools` package. This ensures that the model is trained on one portion of the data and evaluated on another to avoid overfitting.


```{r data-splitting}
set.seed(123) # For reproducibility 
 
 # Load libraries
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)



trainIndex <- createDataPartition(data$diagnosis, p = 0.7, list = FALSE)
train <- data[trainIndex, ]
test  <- data[-trainIndex, ]

### 1. Decision Tree
tree_model <- rpart(diagnosis ~ ., data = train, method = "class")
rpart.plot(tree_model)

# Predictions
tree_pred <- predict(tree_model, test, type = "class")
confusionMatrix(tree_pred, test$diagnosis)

### 2. Random Forest
set.seed(123)
rf_model <- randomForest(diagnosis ~ ., data = train, ntree = 500, importance = TRUE)

# Predictions
rf_pred <- predict(rf_model, test)
confusionMatrix(rf_pred, test$diagnosis)

# Feature importance
importance(rf_model)
varImpPlot(rf_model)

```

## Build the Logistic Regression Model

A logistic regression model is built using `glm()` funciton:

- The formula `diagnosis ~.` specifies that all features should be used to predict the diagnosis variable.
- The `family = binomial` argument indicates that this is a logistic regression model.
- The models summary is displayed to interpret the coefficients and their significance.



## Predict on the Test Set

The model is used to predict probabilites for the test set using `predict()` function. These probabilities are converted into class predictions(`M` for Malignant and `B` for Benign) based on a threshold of 0.5.


```{r predict-test}
# Logistic Regression Model
log_model <- glm(diagnosis ~ ., data = train, family = binomial)

# Predictions (probabilities)
log_prob <- predict(log_model, test, type = "response")

# Convert probabilities to class (threshold = 0.5)
log_pred <- ifelse(log_prob > 0.5, "M", "B")
log_pred <- factor(log_pred, levels = c("B", "M"))

# Confusion Matrix
confusionMatrix(log_pred, test$diagnosis)

# ROC curve and AUC
library(pROC)
roc_obj <- roc(test$diagnosis, log_prob, levels = c("B","M"))
plot(roc_obj, col = "blue")
auc(roc_obj)


```

## Evaluate the Model

The models performance is evaluated using several metrics:

- *Confusion Matrix*: The confusionMatrix() function from the `caret` package provides a detailed breakdown of true positives, true negatives, false positives, and false negatives.

- *Accuracy, Precision, Recall*: These metrics are calculated from the confusion matrix to assess the model performance.

- *ROC Curve and AUC*: The ROC curve is plotted using the `roc()` function from the `pROC` package to generate ROC curve which is used to visualise the trade-off between sensitivity and specificity at various thresholds, while the `auc()` caluculated the Area Under the Curev (AUC) value is calculated to evaluate the model`s ability to distinguish between classes. A higher AUC (closer to 1) indicates better performance.




```{r model-evaluation}

# Confusion Matrix
confusion_matrix <- confusionMatrix(test_data$predicted_class, test_data$diagnosis)     
print(confusion_matrix) 
# Accuracy, Precision, Recall
accuracy <- confusion_matrix$overall['Accuracy']
precision <- confusion_matrix$byClass['Pos Pred Value']
recall <- confusion_matrix$byClass['Sensitivity']
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")

# ROC Curve and AUC

roc_curve <- roc(test_data$diagnosis, test_data$predicted_prob, levels = c("B", "M"))
plot(roc_curve, col = "blue", main = "ROC Curve")
auc_value <- auc(roc_curve)

cat("AUC:", auc_value, "\n")

```

## Conclusion

In this project, I successfully developed a logistic regression model to predict breast cancer diagnosis based on clinical and demographic features. The model achieved an accuracy of `r round(accuracy, 2)`, a precision of `r round(precision, 2)`, and a recall of `r round(recall, 2)`. The AUC value of `r round(auc_value, 2)` indicates that the model has a good ability to distinguish between malignant and benign tumors.
The analysis also highlighted important features that contribute to the prediction, which can be valuable for clinical decision-making. Future work could involve exploring more advanced machine learning techniques, such as random forests or support vector machines, to potentially improve predictive performance. Additionally, further feature engineering and hyperparameter tuning could enhance the model's accuracy and robustness. Overall, this project demonstrates the application of logistic regression in a healthcare context and provides insights into breast cancer prediction.


